搜索引擎，通常指的是收集了万维网上几千万到几十亿个[网页](https://baike.baidu.com/item/网页/99347)并对网页中的每一个词（即关键词）进行索引，建立[索引数据库](https://baike.baidu.com/item/索引数据库/5394111)的[全文搜索引擎](https://baike.baidu.com/item/全文搜索引擎/7847410)。当用户查找某个关键词的时候，所有在页面内容中包含了该关键词的网页都将作为搜索结果被搜出来。再经过复杂的算法进行排序(或者包含商业化的竞价排名、商业推广或者广告)后，这些结果将按照与搜索关键词的相关度高低（或与相关度毫无关系），依次排列。   				

​																																										-------百度百科

- **引擎结构**

  [搜索引擎](https://baike.baidu.com/item/搜索引擎/104812)基本结构一般包括:搜索器、索引器、检索器、用户接口等四个功能模块。

  1）搜索器，也叫网络蜘蛛，是搜索引擎用来爬行和抓取网页的一个自动程序，在系统后台不停歇地在互联网各个节点爬行，在爬行过程中尽可能快的发现和抓取网页。

  2）索引器。它的主要功能是理解搜索器所采集的网页信息，并从中抽取索引项。

  3）检索器。其功能是快速查找文档，进行文档与查询的相关度评价，对要输出的结果进行排序。

  4）用户接口。它为用户提供可视化的查询输入和结果输出的界面。 [1] 

- **分类**

  1、[全文搜索引擎](https://baike.baidu.com/item/全文搜索引擎/7847410)

  全文搜索引擎一般都有一种叫作“网络机器人”或“网络蜘蛛”的软件，这些软件能遍历WEB空间，扫描一定IP范

  [![搜索引擎原理](http://b.hiphotos.baidu.com/baike/s%3D220/sign=463684a795504fc2a65fb707d5dce7f0/a71ea8d3fd1f4134fe120dd12b1f95cad1c85e73.jpg)](https://baike.baidu.com/pic/搜索引擎原理/11054474/0/a71ea8d3fd1f4134fe120dd12b1f95cad1c85e73?fr=lemma&ct=single)搜索引擎原理

  围内的网站，并延着网络上的链接从一个网页到另一个网页，从一个网站到另一个网站采集网页资料。为了保持网页资料的最新，它还会回访已抓取的网页。对已经抓取到的网页，搜索引擎还会用一定的程序进行分析，根据一定的相关度算法建立网页索引，添加到索引数据库中。全文搜索引擎因为依靠软件进行采集网页，所以数据库的容量非常庞大，但是，它的查询结果往往不够准确。我们平时看到的全文搜索引擎，实际上是只是一个搜索引擎的搜索界面。当我们输入关键字进行查询时，搜索引擎便会从宠大的索引数据库中找到包含该关键字的所有相关网页的索引，并按一定的排名规则呈现给我们。不同的搜索引擎，网页索引数据库也不同，排名规则也不尽相同，所以当我们以同一关键字在不同的搜索引擎上进行查询时，搜索的结果和排列顺序通常也不相同。

  2、分类目录搜索引擎

  和全文搜索引擎一样，分类目录搜索引擎的整个工作过程同样也经过收集信息、分析信息和查询信息三部分，只不过分类目录搜索引擎的前两部分，收集信息和分析信息全部由人工来完成。分类目录一般都有专门的编辑人员，负责收集网站的信息。分类目录依靠人工收集和整理网站，能够提供更为准确的查询结果，但收集的内容却非常有限。

  3、元搜索引擎

  这类搜索引擎一般都没有自己的网页搜索软件以及数据库，它的搜索结果是通过调用、控制和优化其它多个独立搜索引擎的搜索结果并以一定的格式在同一界面集中显示。通常元搜索引擎在索引请求提交、检索接口代理和检索接口显示等方面，均有自己开发的具有特色的[元搜索](https://baike.baidu.com/item/元搜索/8307035)技术。在搜索结果上，这些元搜索引擎往往搜索范围更大一些。

  4、集成搜索引擎

  集成搜索引擎是通过网络技术在一个网页上链接很多个独立的搜索引擎，查询时，点选或指定搜索引擎，一次输入，多个搜索引擎同时查询。搜索的结果由各个搜索引擎分别以不同的页面显示。 [2] 

- **工作原理**

  搜索引擎的工作原理是从互联网上抓取网页，建立索引数据库，在索引数据库中搜索排序。它的整个工作过程大体分为信息采集、信息分析、信息查询和用户接口四部分。信息采集是网络机器人扫描一定IP地址范围内的网站，通过链接遍历Web空间，来进行采集网页资料，为保证采集的资料最新，网络机器人还会回访已抓取过的网页；信息分析是通过分析程序，从采集的信息中提取索引项，用索引项表示[文档](https://baike.baidu.com/item/文档/1009768)并生成文档库的索引表，从而建立索引数据库；信息查询是指用户以关键词查找信息时，搜索引擎会根据用户的查询条件在索引库中快速检索文档，然后对检出的文档与查询条件的相关度进行评价，最后根据相关度对检索结果进行排序并输出。 [3] 

- **工作流程**

  爬行和抓取
  搜索引擎派出一个能够在网上发现新网页并抓文件的程序，这个程序通常称之为蜘蛛（Spider）。搜索引擎从已知的数据库出发，就像正常用户的浏览器一样访问这些网页并抓取文件。搜索引擎通过这些爬虫去爬互联网上的外链，从这个网站爬到另一个网站，去跟踪网页中的链接，访问更多的网页，这个过程就叫爬行。这些新的网址会被存入数据库等待搜索。所以跟踪网页链接是搜索引擎蜘蛛（Spider）发现新网址的最基本的方法，所以反向链接成为搜索引擎优化的最基本因素之一。搜索引擎抓取的页面文件与用户浏览器得到的完全一样，抓取的文件存入数据库。
  建立索引
  蜘蛛抓取的页面文件分解、分析，并以巨大表格的形式存入数据库，这个过程即是索引（index)。在索引数据库中，网页文字内容，关键词出现的位置、字体、颜色、加粗、斜体等相关信息都有相应记录。
  搜索词处理
  用户在搜索引擎界面输入关键词，单击“搜索”按钮后，搜索引擎程序即对搜索词进行处理，如中文特有的分词处理，去除停止词，判断是否需要启动整合搜索，判断是否有拼写错误或错别字等情况。搜索词的处理必须十分快速。
  排序
  对搜索词处理后，搜索引擎程序便开始工作，从索引数据库中找出所有包含搜索词的网页，并且根据排名算法计算出哪些网页应该排在前面，然后按照一定格式返回到“搜索”页面。再好的搜索引擎也无法与人相比，这就是为什么网站要进行搜索引擎优化（SEO）。没有SEO的帮助，搜索引擎常常并不能正确的返回最相关、最权威、最有用的信息。 [4] 

- **数据结构**

  倒排是搜索引擎常用的数据结构之一，倒排索引是指用记录的非主属性值(也叫副键)来查找记录而组织的文件叫倒排文件，即次索引。倒排文件中包括了所有副键值，并列出了与之有关的所有记录主键值，主要用于复杂查询。 与传统的SQL查询不同，在搜索引擎收集完数据的预处理阶段，搜索引擎往往需要一种高效的数据结构来对外提供[检索服务](https://baike.baidu.com/item/检索服务)。而现行最有效的数据结构就是“倒排文件”。倒排文件简单一点可以定义为用文档的关键词作为[索引](https://baike.baidu.com/item/索引)，文档作为索引目标的一种结构（类似于普通书籍中，索引是关键词，书的页面是索引目标）。